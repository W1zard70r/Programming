{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание - линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с признаками (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет из материалов к уроку или по ссылке https://raw.githubusercontent.com/jupiterzhuo/travel-insurance/master/travel%20insurance.csv \n",
    "\n",
    "\n",
    "Описание признаков:\n",
    "\n",
    "* Agency — название страхового агентства\n",
    "* Agency Type — тип страхового агентства\n",
    "* Distribution Channel — канал продвижения страхового агентства\n",
    "* Product Name — название страхового продукта\n",
    "* Duration — длительность поездки (количество дней)\n",
    "* Destination — направление поездки\n",
    "* Net Sales — сумма продаж \n",
    "* Commission (in value) — комиссия страхового агентства\n",
    "* Gender — пол застрахованного\n",
    "* Age — возраст застрахованного\n",
    "\n",
    "Ответ:\n",
    "* Claim — потребовалась ли страховая выплата: «да» — 1, «нет» — 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработайте пропущенные значения и примените написанные функции onehot_encode() и minmax_scale().\n",
    "\n",
    "**Подсказка**: маску для категориальных признаков можно сделать фильтром cat_features_mask = (df.dtypes == \"object\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Agency', 'Agency Type', 'Distribution Channel', 'Product Name',\n",
      "       'Destination', 'Gender'],\n",
      "      dtype='object')\n",
      "Index(['Duration', 'Net Sales', 'Commision (in value)', 'Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# < напишите код здесь > \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import impute\n",
    "\n",
    "def minmax_scale(X: np.array):\n",
    "    if np.all(X.max(axis=0) == X.min(axis=0)):\n",
    "        return (X - X.min(axis=0)).astype(float)\n",
    "    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    return X_std\n",
    "\n",
    "\n",
    "def onehot_encoding(x: np.array):\n",
    "    n = np.size(x)\n",
    "    x_uniq = np.sort(np.unique(x))\n",
    "    m = np.size(x_uniq)\n",
    "    new_array = np.zeros((n, m), int)\n",
    "    for i in range(n):\n",
    "        new_array[i, np.where(x_uniq == x[i])[0][0]] = 1\n",
    "\n",
    "    return new_array\n",
    "\n",
    "\n",
    "df = pd.read_csv('travel insurance.csv')\n",
    "cat_features_mask = ((df.dtypes == \"object\")).values # Категориальные признаки\n",
    "num_columns = df.columns[~cat_features_mask] # Числовые признаки\n",
    "cat_columns = df.columns[cat_features_mask] #Категориальные признаки\n",
    "cat_columns = np.delete(cat_columns, np.where(cat_columns == 'Claim')) # оставили только признаки\n",
    "# print(cat_columns)\n",
    "# print(num_columns)\n",
    "\n",
    "# получаем столбцы разных признаков\n",
    "df_num = df[num_columns]\n",
    "df_cat = df[cat_columns]\n",
    "\n",
    "# print(df_cat)\n",
    "# print(df_num)\n",
    "\n",
    "# заполнение средним в числовых\n",
    "replacer = impute.SimpleImputer(strategy=\"mean\")\n",
    "df_num_no_ = pd.DataFrame(data = replacer.fit_transform(df_num), columns = df_num.columns)\n",
    "\n",
    "# заполнение \"\" в категориальных признаках и удаление столбца Claim, который не является признаком в данной задаче\n",
    "df_cat_no_ = df_cat.fillna(\"\")\n",
    "\n",
    "# df_num_no_.head()\n",
    "# df_cat_no_.head()\n",
    "\n",
    "# применяем onehot_encode()\n",
    "encoded_cats = np.hstack([onehot_encoding(df_cat_no_[col]) for col in cat_columns])\n",
    "# print(encoded_cats)\n",
    "\n",
    "# применяем minmax_scale()\n",
    "scaled_nums = minmax_scale(df_num_no_)\n",
    "# print(df_num_no_)\n",
    "# print(scaled_nums)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробный анализ и подготовка датасета часто помогают улучшить качество модели. Ниже представлено несколько идей преобразований. Вы можете применить одно или несколько из этих преобразований (а можете не применять), чтобы помочь будущей модели. \n",
    "\n",
    "1. Посмотрите на количественные признаки. Возможно, в некоторых признаках есть выбросы - значения, которые сильно выбиваются. Такие значения полезно удалять. Советуем присмотреться к колонке Duration)\n",
    "\n",
    "2. Можно заметить, что one hot encoding сильно раздувает количество столбцов. Радикальное решение - можно попробовать выбросить все категориальные признаки из датасета.\n",
    "\n",
    "3. Если все-таки оставляете категориальные признаки, то подумайте, как уменьшить количество столбцов после one hot encoding. Признаки с большим количеством значений (Duration - 149! разных стран) можно удалить или попробовать сгруппировать некоторые значения.\n",
    "\n",
    "4. Downsampling. Датасет достаточно большой, разница в классах огромная. Можно уменьшить число наблюдений с частым ответом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# совместим категориальные и численные признаки\n",
    "final_data = np.hstack([encoded_cats, scaled_nums])\n",
    "\n",
    "# Извлечение Ответов\n",
    "y = df[\"Claim\"].apply(lambda x: 1 if x == \"Yes\" else 0).values\n",
    "X = final_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение линейной регрессии (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это задача классификации, но её можно решить с помощью линейной регрессии, если округлять предсказанный ответ до целого и выбирать ближайший по значению ответ из множества {0, 1}.\n",
    "\n",
    "Вынесите признак 'Claim' в вектор ответов и разделите датасет на обучающую и тестовую выборку в соотношении 80 к 20. Зафиксируйте random_state.\n",
    "\n",
    "**Подсказка:** быстро перевести Yes/No в 1/0 можно так - np.where(df['Claim'] == 'Yes', 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение на test/train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "rand_stat = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2 , random_state = rand_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите аналитическое решение для обучающей выборки: обычное и регуляризацией l2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитайте аналитическое решение\n",
    "def regress(X, y):\n",
    "    return np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "\n",
    "X_train_1 = np.hstack([np.ones((X_train.shape[0], 1)), X_train])  # добавляем столбец единичных значений\n",
    "W_normal = regress(X_train_1, y_train)\n",
    "# print(W_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитать аналитическое решение с регуляризацией\n",
    "def L2_regression(X, y, lambda_reg):\n",
    "    n_features = X.shape[1]\n",
    "    I = np.eye(n_features) \n",
    "    return np.linalg.inv(X.T @ X + lambda_reg * I) @ X.T @ y\n",
    "\n",
    "\n",
    "lambda_reg = 1  # Пример значения коэффициента регуляризации\n",
    "W_l2 = L2_regression(X_train_1, y_train, lambda_reg)\n",
    "# print(W_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель LinearRegression, примените к тестовой выборке и посчитайте MSE (можно использовать библиотеку sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучите модель линейной регрессии LinearRegression на обучающей выборке, примените к тестовойfrom sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0\n"
     ]
    }
   ],
   "source": [
    "# посчитайте MSE, предварительно округлив предсказанные ответы до целого\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error (MSE): {round(mse)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод (1 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите краткий вывод по заданию (достаточно пары предложений). Расскажите, какие способы предобработки данных вы выбрали и почему. Насколько хороша ваша модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы использовали преобразования onehot_encode для пролучения матриц, обычные числовые значения мы сделали поближе к друг другу с помощью minmax_scale. Преварительно убрали Claim из списка столбцов. Затем разделили с sklearn split на выборки и посчитали аналитическое решение и решение l2 с лямбой = 1, ну как в на семинаре, далее посчитали метрику MSE и получили наше отклонение. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled9.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
